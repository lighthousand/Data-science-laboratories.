{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "\n",
    "\n",
    "url_iris = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "names = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "df = pd.read_csv(url_iris, names=names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      "sepal length    150 non-null float64\n",
      "sepal width     150 non-null float64\n",
      "petal length    150 non-null float64\n",
      "petal width     150 non-null float64\n",
      "class           150 non-null object\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 5.9+ KB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier\n",
    "\n",
    "# KNN falls in the supervised learning family of algorithms. \n",
    "# Informally, this means that we are given a labelled dataset consiting of training observations (x,y) \n",
    "# and would like to capture the relationship between x and y. More formally, our goal is to learn a \n",
    "# function h:Xâ†’Y so that given an unseen observation x, h(x) can confidently predict the corresponding output y.\n",
    "\n",
    "# LogisticRegresion \n",
    "\n",
    "# Logistic regression is a statistical method for analyzing a dataset in which there are one or more independent \n",
    "# variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there \n",
    "# are only two possible outcomes).\n",
    "# In logistic regression, the dependent variable is binary or dichotomous, i.e. it only contains data coded as 1 \n",
    "# (TRUE, success, pregnant, etc.) or 0 (FALSE, failure, non-pregnant, etc.).\n",
    "# The goal of logistic regression is to find the best fitting (yet biologically reasonable) model to describe \n",
    "# the relationship between the dichotomous characteristic of interest (dependent variable = response or outcome variable) \n",
    "# and a set of independent (predictor or explanatory) variables. Logistic regression generates the coefficients \n",
    "# (and its standard errors and significance levels) of a formula to predict a logit transformation of the probability \n",
    "# of presence of the characteristic of interest:\n",
    "\n",
    "# DecisionTree\n",
    "\n",
    "# Decision Trees (DTs) are a non-parametric supervised learning method used for classification and regression. \n",
    "# The goal is to create a model that predicts the value of a target variable by learning simple decision rules \n",
    "# inferred from the data features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
